# OpenClaw 多 AI 协作流程 v2.0

本文档定义了 OpenClaw 项目中多个 AI 协作的工作流程，确保信息不丢失、决策有记录、质量有保障。

## 角色分工

| AI | 输出 | 不输出 |
|----|------|--------|
| **Gemini** | Facts（代码路径、行号、引用） | Plan、决策 |
| **Claude** | Plan（含验收/回滚/风险） | Facts（原始代码分析） |
| **GPT** | 实施、代码、测试、Verify 步骤 | 架构决策 |
| **人类用户** | 最终决策、触发 gate | - |

## 协作流程

```
┌─────────────────────────────────────────────────────────────┐
│  1. Gemini: Facts                                           │
│     - 只输出事实：文件路径、行号、函数签名、配置项             │
│     - 带引用，不给建议                                       │
├─────────────────────────────────────────────────────────────┤
│  2. Claude: Plan                                             │
│     - 基于 Gemini 的 Facts 做决策                            │
│     - 输出可执行 checklist                                   │
│     - 标注风险等级（低/中/高）                               │
│     - 高风险：含回滚步骤                                     │
├─────────────────────────────────────────────────────────────┤
│  3. GPT: 实施 + 最小测试                                     │
│     - 执行 Plan，写代码                                     │
│     - 跑基本测试                                             │
│     - 报告"已执行的变更 + 剩余 blocker"                      │
├─────────────────────────────────────────────────────────────┤
│  4. Claude: Review（按风险触发）                             │
│     - 低风险：跳过 Review                                    │
│     - 中风险：Review 逻辑/边界情况                           │
│     - 高风险：Review + 威胁模型分析                          │
├─────────────────────────────────────────────────────────────┤
│  5. GPT: 修复 + Gate + Verify                               │
│     - 修复 Review 问题                                       │
│     - 跑 gate（pnpm check + test）                          │
│     - 给 Claude 3 行 Verify 结果                             │
└─────────────────────────────────────────────────────────────┘
```

## Review 触发条件

| 风险等级 | 触发条件 | Claude Review 范围 |
|----------|----------|-------------------|
| **低** | 单文件、小改动 | 跳过 |
| **中** | 跨模块、配置变更、协议改动、用户可见行为 | 逻辑、边界情况 |
| **高** | auth、exec sandbox、token、文件系统、网络暴露 | Review + 威胁模型 + 回滚步骤 |

## 任务文档模板

创建 `TASKS/<yyyy-mm-dd>-<slug>.md`：

```markdown
# <slug>

## Context
- 问题现象/截图/日志

## Facts
- 文件路径:行号 - 内容描述（Gemini 提供）

## Decision
- 最终方案
- 被否决的方案 A: 原因
- 被否决的方案 B: 原因

## Plan
- [ ] 步骤 1
- [ ] 步骤 2
- ...

## Verify
- [ ] 命令/测试/界面行为
```

## 质量门控

每次提交默认至少做到：

```bash
# 最小集合
pnpm check          # lint/format
pnpm test <target>  # 相关测试

# 配置/协议/路由变更：加 1 个单测
```

## 结尾摘要（必须）

每个 AI 结束时输出 3 行：

```
Root cause: ...
Fix: ...
Verify: ...
```

## 避免冲突规则

| 动作 | 谁可以做 |
|------|----------|
| 产生"下一步清单" | **只有 Claude** |
| 给出 Facts | **只有 Gemini** |
| 给出"已执行变更 + blocker" | **只有 GPT** |

## 敏感代码处理

敏感代码（auth、exec、token 等）不由特定 AI 独占，但必须走更严格的 gate：

```
设计审查(Claude) + 测试 + 代码扫描清单
```

也就是"写的人"和"审的人"分离。

---

**Root cause**: 多 AI 协作时信息断层、决策冲突、质量无保障
**Fix**: 定义角色分工、Review 分级、固定模板、3 行摘要
**Verify**: 每个任务按此流程执行，信息记录在 TASKS/ 目录
